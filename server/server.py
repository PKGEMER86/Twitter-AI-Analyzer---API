# Importa le classi necessarie dalla libreria langchain per l'integrazione con l'AI di Google
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import AIMessage, HumanMessage, SystemMessage
from dotenv import load_dotenv, find_dotenv
from flask import Flask, request, jsonify

# Carica le variabili d'ambiente dal file .env
load_dotenv(find_dotenv())

# Crea un'istanza di Flask per il web server
app = Flask(__name__)

# Crea un'istanza del modello AI di Google Generative AI con un modello specifico
model = ChatGoogleGenerativeAI(model="gemini-1.5-flash")

# Esempio di tweet per testare le funzioni
tweet_example = "üåû Buongiorno a tutti! Oggi √® una giornata perfetta per una passeggiata all'aria aperta. üèûÔ∏è Non dimenticate di prendere un po' di tempo per voi stessi e godervi la natura! üå≥‚ú® #Buongiorno #Relax #VivereBene"

# Funzione per valutare la viralit√† di un tweet basata su un prompt
def evaluate_virality(tweet_prompt):
    viralit√† = [
        # Messaggio di sistema che specifica il ruolo dell'AI nell'analisi della viralit√† del tweet
        SystemMessage(content="Agisci come un Twitter AI Analyzer. Hai 10 anni di esperienza nel capire e valutare la possibilit√† che vada virale un Twitter. Dammi una valutazione di viralit√† da 1 a 10. Dammi solo il numero di valutazione non rispondere con altri informazioni. Ecco il mio tweet"),
        # Messaggio umano con l'esempio di tweet da analizzare
        HumanMessage(content=tweet_example),
        # Risposta dell'AI (esempio) sulla viralit√† del tweet
        AIMessage(content="4/10"),  # Questo √® un valore di esempio. Considera di rimuovere o modificare se necessario.
        # Messaggio umano con il tweet da valutare
        HumanMessage(content=tweet_prompt)
    ]
    # Invoca il modello AI con i messaggi e restituisce il contenuto della risposta dell'AI
    return model.invoke(viralit√†).content

# Funzione per fornire feedback su un tweet in base alla sua valutazione di viralit√†
def provide_feedback(tweet_prompt, viralit√†_r):
    feedback = [
        # Messaggio di sistema che specifica il ruolo dell'AI nel fornire feedback testuale sul tweet
        SystemMessage(content=f"Agisci come un Twitter AI Analyzer. Hai 10 anni di esperienza nel dare feedback ai Twitter. Ti dar√≤ un tweet che ha una probabilit√† di andare virale di {viralit√†_r} e tu mi dirai un feedback testuale. Non darmi dei tweet migliorati o valutazioni tue. Dammi solo un feedback testuale."),
        # Messaggio umano con l'esempio di tweet da cui trarre feedback
        HumanMessage(content=tweet_example),
        # Risposta dell'AI (esempio) con il feedback sul tweet
        AIMessage(content="Il tweet ha un messaggio positivo e incoraggiante, che pu√≤ risuonare bene con chi cerca ispirazione per la giornata. Tuttavia, potrebbe non avere un impatto virale elevato poich√© √® piuttosto generico e privo di elementi distintivi o di attualit√†. Per aumentare la probabilit√† di viralit√†, potresti considerare di aggiungere un elemento personale, una storia breve o una domanda che stimoli la partecipazione degli utenti. Inoltre, l'uso di hashtag √® corretto, ma una combinazione di hashtag pi√π mirati o di tendenze attuali potrebbe aiutare a raggiungere un pubblico pi√π ampio."),
        # Messaggio umano con il tweet da cui fornire feedback
        HumanMessage(content=tweet_prompt)
    ]
    # Invoca il modello AI con i messaggi e restituisce il contenuto della risposta dell'AI
    return model.invoke(feedback).content

# Funzione per migliorare un tweet per raggiungere una viralit√† massima
def improve_tweet(tweet_prompt, viralit√†_r):
    improve = [
        # Messaggio di sistema che specifica il ruolo dell'AI nel migliorare il tweet per ottenere una viralit√† massima
        SystemMessage(content=f"Agisci come un Twitter AI Analyzer. Hai 10 anni di esperienza nel generare dei tweet con viralit√† 10/10. Ti dar√≤ un tweet che ha una probabilit√† di andare virale di {viralit√†_r} e lo rigenererai per ottenere un tweet con viralit√† 10/10. Non fornirmi altre spiegazioni o informazioni ulteriori. Dammi solo il tweet migliorato con viralit√† 10/10."),
        # Messaggio umano con l'esempio di tweet da migliorare
        HumanMessage(content=tweet_example),
        # Risposta dell'AI (esempio) con il tweet migliorato per massimizzare la viralit√†
        AIMessage(content="üåü Buongiorno, Twitter! üåü Oggi √® il giorno ideale per una passeggiata nella natura e un po' di tempo per te stesso! üö∂‚Äç‚ôÇÔ∏èüå≥ Prenditi una pausa, respira profondamente e ricarica le energie. üíö‚ú® #ViviAlMassimo #Natura #SelfCare"),
        # Messaggio umano con il tweet da migliorare
        HumanMessage(content=tweet_prompt)
    ]
    # Invoca il modello AI con i messaggi e restituisce il contenuto della risposta dell'AI
    return model.invoke(improve).content

# Definisce una route per l'API Flask che gestisce le richieste POST per "/TAIAPI"
@app.route("/TAIAPI", methods=['POST'])
def main():
    # Estrae il tweet dal corpo della richiesta JSON
    tweet_prompt = request.json.get("tweet_prompt")
    # Controlla se il tweet √® presente nella richiesta
    if not tweet_prompt:
        return jsonify({"error": "Tweet is required"}), 400

    try:
        # Valuta la viralit√† del tweet, fornisce feedback e migliora il tweet
        viralit√†_r = evaluate_virality(tweet_prompt)
        feedback_r = provide_feedback(tweet_prompt, viralit√†_r)
        improve_r = improve_tweet(tweet_prompt, viralit√†_r)
        
        # Restituisce le valutazioni e il feedback in formato JSON
        return jsonify({
            "viralit√†": viralit√†_r,
            "feedback": feedback_r,
            "improve": improve_r
        }), 201

    except Exception as e:
        # Gestisce gli errori e restituisce un messaggio di errore
        return jsonify({"error": str(e)}), 500

# Avvia il server Flask se il file viene eseguito direttamente
if __name__ == "__main__":
    app.run(debug=False)
